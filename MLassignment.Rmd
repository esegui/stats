---
title: "ML Assignment "
output: html_document
---

```{r}
library(caret)
library(corrplot)
library(rpart)
library(rattle)
```


# Data Cleaning

```{r}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
label <- createDataPartition(training$classe, p = 0.7, list = FALSE)
train <- training[label, ]
test <- training[-label, ]
```

From among 160 variables present in the dataset, some variables have nearly zero variance whereas some contain a lot of NA terms which need to be excluded from the dataset. Moreover, other 5 variables used for identification can also be removed. 


```{r}
zero <- nearZeroVar(train)
train <- train[ ,-zero]
test <- test[ ,-zero]
NAcolumns <- c()
for (i in 1:ncol(train)) {
  sum <- sum(is.na(train[[i]]))
  if (sum > (nrow(train)*0.95)) {
   NAcolumns[i] <- i  
  }
}
NAcolumns <- na.omit(NAcolumns)
train <- train[ , -NAcolumns]
test <- test[ , -NAcolumns]

train <- train[ , -c(1:5)]
test <- test[ , -c(1:5)]
dim(train)
```
 160 variables down to 54.

## Exploratory Analysis

```{r}
corr <- cor(train[,-54])
corrplot(corr, method = "color")
```

Only a couple variables have multicollinearity

## 3 Prediction Models

### Decision Tree

```{r}
set.seed(123)
modeltree <- rpart(classe ~ ., data = train, method = "class")
fancyRpartPlot(modeltree)
predicttree <- predict(modeltree, test, type = "class")
conftree <- confusionMatrix(predicttree, as.factor(test$classe))
conftree
```

Accuracy : 0.75        
Kappa : 0.68         


### Random Forest


```{r}
set.seed(123)
control <- trainControl(method = "cv", number = 3, verboseIter=FALSE)
modelRF <- train(classe ~ ., data = train, method = "rf", trControl = control)
modelRF$finalModel
predictRF <- predict(modelRF, test)
confRF <- confusionMatrix(predictRF, as.factor(test$classe))
confRF
```
Accuracy : 0.9985          
Kappa : 0.9981          

### Generalized Boosted Model
```{r}
set.seed(123)
control <- trainControl(method = "repeatedcv", number = 5, repeats = 1, verboseIter = FALSE)
modelGBM <- train(classe ~ ., data = train, trControl = control, method = "gbm", verbose = FALSE)
modelGBM$finalModel
predictGBM <- predict(modelGBM, test)
confGBM <- confusionMatrix(predictGBM, as.factor(test$classe))
confGBM
```

Accuracy : 0.9864         
Kappa : 0.9828          

Random Forest has maximum accuracy of 99.8%

## Prediction with Testing Set
```{r}
predictRF <- predict(modelRF, testing)
predictRF
```
